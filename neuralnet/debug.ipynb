{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juampablo/miniconda3/envs/torch/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01margparse\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m trans\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LoadDatasetswDomain\n",
      "File \u001b[0;32m~/Desktop/FinalProjectCSE547/neuralnet/utils.py:29\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# from models import model_GAN_segmentation\u001b[39;00m\n\u001b[1;32m     23\u001b[0m LOSS_STR_TO_FUNC \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m: nn\u001b[38;5;241m.\u001b[39mMSELoss(),\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcross-entropy\u001b[39m\u001b[38;5;124m'\u001b[39m: nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss(),\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmask-regulizer\u001b[39m\u001b[38;5;124m'\u001b[39m: lf2\u001b[38;5;241m.\u001b[39mMaskregulizer(),\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge-loss\u001b[39m\u001b[38;5;124m'\u001b[39m: EdgeLoss3D\u001b[38;5;241m.\u001b[39mGMELoss3D(),\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdice\u001b[39m\u001b[38;5;124m'\u001b[39m: lf\u001b[38;5;241m.\u001b[39mDiceLoss(),\n\u001b[0;32m---> 29\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfocal\u001b[39m\u001b[38;5;124m'\u001b[39m: lf\u001b[38;5;241m.\u001b[39mFocalLoss()\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;66;03m# 'hd'\u001b[39;00m\n\u001b[1;32m     31\u001b[0m }\n\u001b[1;32m     33\u001b[0m MODEL_STR_TO_FUNC \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     34\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mautoencoder-with-classifier\u001b[39m\u001b[38;5;124m'\u001b[39m: model\u001b[38;5;241m.\u001b[39mDANNEncoderDecoder3D(),\n\u001b[1;32m     35\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124munet-DANN\u001b[39m\u001b[38;5;124m'\u001b[39m: model\u001b[38;5;241m.\u001b[39mDANNUNet3D(),\n\u001b[1;32m     36\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mextended-latent-unet-DANN\u001b[39m\u001b[38;5;124m'\u001b[39m: model\u001b[38;5;241m.\u001b[39mDANNUNet3DExtendedLatent()\n\u001b[1;32m     37\u001b[0m \n\u001b[1;32m     38\u001b[0m } \u001b[38;5;66;03m# All models here have output: [segmentation, classification, latent]\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msplit_seg_labels\u001b[39m(seg):\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;66;03m# Split the segmentation labels into 3 channels\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/FinalProjectCSE547/neuralnet/losses/EdgeLoss3D.py:120\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, criterion, n1, n2, n3, device)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39medge_filter \u001b[38;5;241m=\u001b[39m GradEdge3D(n1, n2, n3, device)\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion \u001b[38;5;241m=\u001b[39m criterion\n\u001b[0;32m--> 120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, y, yp):\n\u001b[1;32m    121\u001b[0m     y_edge \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39medge_filter\u001b[38;5;241m.\u001b[39mdetect(y)\n\u001b[1;32m    122\u001b[0m     yp_edge \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39medge_filter\u001b[38;5;241m.\u001b[39mdetect(yp)\n",
      "File \u001b[0;32m~/Desktop/FinalProjectCSE547/neuralnet/losses/EdgeLoss3D.py:84\u001b[0m, in \u001b[0;36mGradEdge3D.__init__\u001b[0;34m(self, n1, n2, n3, device)\u001b[0m\n\u001b[1;32m     80\u001b[0m sobel_filter \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mConv3d(in_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, out_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     81\u001b[0m                          kernel_size\u001b[38;5;241m=\u001b[39mk_sobel, padding\u001b[38;5;241m=\u001b[39mk_sobel \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m, bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     82\u001b[0m sobel_filter\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(\n\u001b[1;32m     83\u001b[0m     s\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32))\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, k_sobel, k_sobel, k_sobel)\n\u001b[0;32m---> 84\u001b[0m sobel_filter \u001b[38;5;241m=\u001b[39m sobel_filter\u001b[38;5;241m.\u001b[39mto(device, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msobel_filters\u001b[38;5;241m.\u001b[39mappend(sobel_filter)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.11/site-packages/torch/nn/modules/module.py:1145\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply(convert)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.11/site-packages/torch/nn/modules/module.py:820\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 820\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m fn(param)\n\u001b[1;32m    821\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.11/site-packages/torch/nn/modules/module.py:1143\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.11/site-packages/torch/cuda/__init__.py:239\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    236\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    237\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 239\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    242\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import torch\n",
    "from utils import *\n",
    "from data import trans\n",
    "from data.datasets import LoadDatasetswDomain\n",
    "\n",
    "# import transforms ####\n",
    "from torchvision import transforms\n",
    "from train_utils import load_fold_file\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import os\n",
    "from torch import optim, nn, utils, Tensor\n",
    "from torchvision.transforms import ToTensor\n",
    "import lightning as L\n",
    "from lightning.pytorch.cli import LightningCLI\n",
    "\n",
    "from lightning.pytorch import Trainer, seed_everything\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "\n",
    "from train_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Lightning Module \n",
    "class LitGoAT(L.LightningModule):\n",
    "    def __init__(self, model, alpha, init_lr, train_on_overlap, eval_on_overlap, loss_functions, loss_weights, weights, power, max_epochs):\n",
    "        super().__init__()\n",
    "        self.model  = model \n",
    "        self.init_lr = init_lr\n",
    "        self.train_on_overlap = train_on_overlap\n",
    "        self.eval_on_overlap = eval_on_overlap\n",
    "        self.loss_functions = loss_functions\n",
    "        self.loss_weights = loss_weights\n",
    "        self.domain_criterion = nn.BCELoss()\n",
    "        self.alpha = alpha\n",
    "        self.weights = weights\n",
    "        self.power\n",
    "        self.max_epochs = max_epochs\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_loss(output, seg, loss_functs, loss_weights):\n",
    "        \"\"\"Computes weighted loss between model output and ground truth, summed across each region.\"\"\"\n",
    "        loss = 0.\n",
    "        for n, loss_function in enumerate(loss_functs):      \n",
    "            temp = 0\n",
    "            for i in range(3):\n",
    "                temp += loss_function(output[:,i:i+1], seg[:,i:i+1])\n",
    "\n",
    "            loss += temp * loss_weights[n]\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx): \n",
    "\n",
    "        subject_id, imgs, true_classification = batch\n",
    "\n",
    "        # Unpack the data\n",
    "        x1 = imgs[0]\n",
    "        x2 = imgs[1]\n",
    "        x3 = imgs[2]\n",
    "        x4 = imgs[3]\n",
    "        seg = imgs[4]\n",
    "\n",
    "        seg3 = split_seg_labels(seg)\n",
    "\n",
    "        # Set the target either as overlapping or disjoint regions\n",
    "        if self.train_on_overlap:\n",
    "            # Combine the segmentation labels into partially overlapping regions\n",
    "            mask = torch.zeros_like(seg3)\n",
    "            mask[:,0] = seg3[:, 0] + seg3[:, 1] + seg3[:, 2] #WHOLE TUMOR\n",
    "            mask[:,1] = seg3[:, 0] + seg3[:, 2] #TUMOR CORE\n",
    "            mask[:,2] = seg3[:, 2] #ENHANCING TUMOR\n",
    "            mask = mask.float()\n",
    "        else:\n",
    "            mask = seg3.float()\n",
    "\n",
    "        x_in = torch.cat((x1, x2, x3, x4), dim=1)\n",
    "\n",
    "        output, pred_classification, latent = self(x_in, self.alpha) # equivalent to self.model(x_in)\n",
    "        output = output.float()\n",
    "\n",
    "        segmentation_loss = self.compute_loss(output, seg, self.loss_functions, self.weights)\n",
    "        classifier_loss = self.domain_criterion(pred_classification, true_classification)\n",
    "\n",
    "        loss = self.loss_weights[0]*segmentation_loss + self.loss_weights[1]*classifier_loss\n",
    "\n",
    "        # Log losses to TensorBoard (changing to WandB soon..)\n",
    "        self.log(\"seg_loss\", segmentation_loss, on_step=False, on_epoch=True)\n",
    "        self.log(\"classif_loss\", classifier_loss, on_step=False, on_epoch=True)\n",
    "        self.log(\"backprop_loss\", loss, on_step=False, on_epoch=True)\n",
    "        self.log('epoch_loss', loss, on_step=False, on_epoch=True) # Logs mean loss per epoch\n",
    "\n",
    "\n",
    "        if true_classification == 1:\n",
    "            self.log(\"SSA_seg_loss\", segmentation_loss)\n",
    "            self.log(\"SSA_classif_loss\", classifier_loss)\n",
    "        elif true_classification == 0:\n",
    "            self.log(\"GLI_seg_loss\", segmentation_loss)\n",
    "            self.log(\"GLI_classif_loss\", classifier_loss)\n",
    "        else:\n",
    "            print(\"Classification not understood..\")\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        if self.calculate_eval_metrics == False:\n",
    "            \n",
    "\n",
    "        \n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=self.init_lr, weight_decay = 0, amsgrad= True)\n",
    "        lr_scheduler = {\n",
    "            'scheduler': torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=self.lr_lambda),\n",
    "            'interval': 'epoch',  \n",
    "            'frequency': 1\n",
    "        }\n",
    "        return [optimizer], [lr_scheduler]\n",
    "\n",
    "    def lr_lambda(self, current_epoch):\n",
    "        \"\"\"Custom learning rate scheduler.\"\"\"\n",
    "        return np.power(1 - (current_epoch / self.max_epochs), self.power)\n",
    "\n",
    "\n",
    "# Lightning Data Module    \n",
    "class BraTSDataModule(L.LightningDataModule):\n",
    "    def __init__(self, data_dir: str = \"path/to/dir\", batch_size: int = 1, test_data_dir: str = \"path/to/dir\", folds_dir: str = \"path/to/dir\", fold_no: int = 0):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.test_data_dir = test_data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.folds_dir = folds_dir\n",
    "        self.fold_no = fold_no\n",
    "        self.transforms = transforms.Compose([trans.CenterCropBySize([128,192,128]), \n",
    "                                              trans.NumpyType((np.float32, np.float32,np.float32, np.float32,np.float32)),\n",
    "                                              ])\n",
    "\n",
    "\n",
    "    def setup(self, stage: str):\n",
    "        train_file_names, val_file_names = self.load_file_names(self.data_dir, self.folds_dir, self.fold_no)\n",
    "        \n",
    "        if stage == 'fit':\n",
    "            self.brats_train = LoadDatasetswDomain(self.data_dir, self.transforms, train_file_names)\n",
    "            self.brats_val = LoadDatasetswDomain(self.data_dir, self.transforms, val_file_names)\n",
    "        if stage == 'test':\n",
    "            self.brats_test = LoadDatasetswDomain(self.test_data_dir, self.transforms, os.listdir(self.test_data_dir)) # currently uses val NEED TO CHANGE to test\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.brats_train, batch_size=self.batch_size)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.brats_val, batch_size=self.batch_size) \n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.brats_test, batch_size=self.batch_size) \n",
    "\n",
    "    @staticmethod\n",
    "    def load_file_names(data_dir, folds_dir, fold_no):\n",
    "        val_dir = os.path.join(folds_dir , sorted( os.listdir(folds_dir) )[fold_no])\n",
    "        val_file_names = load_fold_file(val_dir)\n",
    "        train_file_names = [name for name in os.listdir(data_dir) if name not in val_file_names]\n",
    "        return train_file_names, val_file_names\n",
    "    \n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    (alpha, train_dir, test_dir, ckpt_dir, out_dir, loss_str, weights, loss_weights, \n",
    "            model_str, partial_file_names, folds_dir, fold_no, max_epochs, lr, power, eval_on_overlap, train_on_overlap) = parse_args()\n",
    "\n",
    "\n",
    "    model_architecture = LOSS_STR_TO_FUNC[model_str]\n",
    "    alpha = alpha\n",
    "    init_lr = lr\n",
    "    train_on_overlap = train_on_overlap\n",
    "    eval_on_overlap = eval_on_overlap\n",
    "    loss_functions = [LOSS_STR_TO_FUNC[l] for l in loss_str]\n",
    "    loss_weights = loss_weights\n",
    "    power =  power\n",
    "    max_epochs = max_epochs\n",
    "\n",
    "    data_dir = train_dir\n",
    "    batch_size = 1\n",
    "    test_data_dir = test_dir\n",
    "    folds_dir = folds_dir\n",
    "    fold_no = fold_no\n",
    "\n",
    "    new_ckpt_dir = os.path.join(out_dir, 'new_checkpoints')\n",
    "    if not os.path.exists(new_ckpt_dir):\n",
    "        os.makedirs(new_ckpt_dir)\n",
    "        os.system('chmod a+rwx ' + new_ckpt_dir)\n",
    "\n",
    "    # Instantiate DataModule\n",
    "    dm = BraTSDataModule(data_dir = data_dir, batch_size = batch_size, test_data_dir = test_data_dir, folds_dir = folds_dir, fold_no = fold_no)\n",
    "    \n",
    "    # Instantiate Trainer\n",
    "    seed_everything(42, workers = True) # sets seeds for numpy, torch and python.random.\n",
    "    checkpoint_callback = ModelCheckpoint(every_n_epochs = 2, dirpath=new_ckpt_dir, filename=\"train-GoAT-{epoch:02d}-{seg_loss:.2f}\")\n",
    "    trainer = Trainer(max_epochs=max_epochs, default_root_dir=out_dir, deterministic = True) # Will automatically train with system devices and the maximum number of GPUs available (see documentation here: https://lightning.ai/docs/pytorch/stable/common/trainer.html)\n",
    "\n",
    "    model = LitGoAT(model_architecture, alpha, init_lr, train_on_overlap, eval_on_overlap, loss_functions, loss_weights, weights, power, max_epochs)\n",
    "    if ckpt_dir is not None:\n",
    "        model = LitGoAT.load_from_checkpoint(ckpt_dir)\n",
    "\n",
    "    trainer.fit(model, datamodule=dm)\n",
    "    trainer.validate(datamodule=dm)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
